{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup and Data Loading\n",
        "We will use a popular, pre-packaged dataset for speed.\n",
        "This code prepares the movie reviews dataset for sentiment analysis. It does the following:\n",
        "\n",
        "Imports libraries for data handling, machine learning, and natural language processing.\n",
        "\n",
        "Downloads NLTK resources needed for the dataset, stopwords, and tokenization.\n",
        "\n",
        "Loads all movie reviews, pairing each review with its sentiment label (positive or negative).\n",
        "\n",
        "Creates a pandas DataFrame with two columns: the review text and its sentiment.\n",
        "\n",
        "Encodes sentiment numerically: 1 for positive, 0 for negative, which is suitable for machine learning.\n",
        "\n",
        "Prints a summary showing total reviews, counts of positive and negative reviews, and sample data."
      ],
      "metadata": {
        "id": "cfptpkGcTz9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLXyOyxoRsl-",
        "outputId": "6af224c6-e19e-424e-f9e7-3ae47bcde746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading NLTK resources...\n",
            "NLTK resources downloaded successfully.\n",
            "--- Data Loading Complete ---\n",
            "Total reviews loaded: 2000\n",
            "Positive reviews: 1000\n",
            "Negative reviews: 1000\n",
            "\n",
            "Sample Data:\n",
            "                                              review sentiment  \\\n",
            "0  plot : two teen couples go to a church party ,...       neg   \n",
            "1  the happy bastard ' s quick movie review damn ...       neg   \n",
            "2  it is movies like these that make a jaded movi...       neg   \n",
            "3  \" quest for camelot \" is warner bros . ' first...       neg   \n",
            "4  synopsis : a mentally unstable man undergoing ...       neg   \n",
            "\n",
            "   sentiment_encoded  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "\n",
        "print(\"Downloading NLTK resources...\")\n",
        "try:\n",
        "    nltk.download('movie_reviews', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    print(\"NLTK resources downloaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading NLTK resources: {e}\")\n",
        "\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "data = {'review': [' '.join(words) for words, category in documents],\n",
        "        'sentiment': [category for words, category in documents]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df['sentiment_encoded'] = df['sentiment'].apply(lambda x: 1 if x == 'pos' else 0)\n",
        "\n",
        "print(\"--- Data Loading Complete ---\")\n",
        "print(f\"Total reviews loaded: {len(df)}\")\n",
        "print(f\"Positive reviews: {df['sentiment'].value_counts()['pos']}\")\n",
        "print(f\"Negative reviews: {df['sentiment'].value_counts()['neg']}\")\n",
        "print(\"\\nSample Data:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Text Preprocessing and Vectorization (Feature Engineering)\n",
        "We will use the TF-IDF (Term Frequency-Inverse Document Frequency) method to convert text into numerical features.\n",
        "\n",
        "Separate features and labels:\n",
        "\n",
        "- X contains the review text.\n",
        "\n",
        "- y contains the numerical sentiment labels (1 = positive, 0 = negative).\n",
        "\n",
        "Split the data into training (80%) and testing (20%) sets.\n",
        "\n",
        "- stratify=y ensures both sets have the same proportion of positive and negative reviews.\n",
        "\n",
        "Convert text into numerical features using TF-IDF:\n",
        "\n",
        "- TF-IDF measures how important a word/phrase is in a review relative to the dataset.\n",
        "\n",
        "- max_features=5000 limits to the 5000 most important words/phrases.\n",
        "\n",
        "- stop_words='english' ignores common words like “the” or “is”.\n",
        "\n",
        "- ngram_range=(1, 2) uses single words (1-grams) and pairs of words (2-grams) as features.\n",
        "\n",
        "Fit and transform training data (X_train_vec) and transform testing data (X_test_vec).\n",
        "\n",
        "- The model will learn patterns from X_train_vec.\n",
        "\n",
        "Print summary:\n",
        "\n",
        "- Shapes of training and testing data (number of reviews × number of features)\n",
        "\n",
        "- Total number of features (words/phrases) extracted"
      ],
      "metadata": {
        "id": "YlRS8stcT8US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['review']\n",
        "y = df['sentiment_encoded']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
        "\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"\\nVectorization Complete.\")\n",
        "print(f\"Training data shape: {X_train_vec.shape}\")\n",
        "print(f\"Testing data shape: {X_test_vec.shape}\")\n",
        "print(f\"Number of features (words/phrases): {len(vectorizer.get_feature_names_out())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHE99MaNR33U",
        "outputId": "0b5fc5dc-786c-4826-8fa7-b11a67451fc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vectorization Complete.\n",
            "Training data shape: (1600, 5000)\n",
            "Testing data shape: (400, 5000)\n",
            "Number of features (words/phrases): 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Model Training (Logistic Regression)\n",
        "Logistic Regression is fast and highly effective for binary text classification.\n",
        "\n",
        "## Create the model:\n",
        "\n",
        "- LogisticRegression is a simple and effective algorithm for binary classification (positive vs negative).\n",
        "\n",
        "- max_iter=1000 allows the model enough iterations to converge.\n",
        "\n",
        "- random_state=42 ensures reproducible results.\n",
        "\n",
        "## Train the model:\n",
        "\n",
        "- model.fit(X_train_vec, y_train) tells the model to learn patterns from the training data vectors (X_train_vec) and their corresponding labels (y_train).\n",
        "\n",
        "## Print messages:\n",
        "\n",
        "- Shows when training starts and when it finishes."
      ],
      "metadata": {
        "id": "GYWV0EgGUkCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "print(\"\\nStarting Model Training...\")\n",
        "model.fit(X_train_vec, y_train)\n",
        "print(\"Model Training Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqCDAhp1SkNy",
        "outputId": "4ebcaa5d-7b49-4d12-cb93-d7ee9492fa6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Model Training...\n",
            "Model Training Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Evaluation and Results\n",
        "Now we evaluate the model's performance on unseen data.\n",
        "\n",
        "## Make predictions:\n",
        "\n",
        "- y_pred = model.predict(X_test_vec) uses the trained model to predict the sentiment of the testing reviews.\n",
        "\n",
        "## Calculate accuracy:\n",
        "\n",
        "- accuracy_score(y_test, y_pred) computes the percentage of correct predictions.\n",
        "\n",
        "- Accuracy tells us how often the model gets it right.\n",
        "\n",
        "## Generate detailed metrics:\n",
        "\n",
        "- classification_report shows precision, recall, and F1-score for both classes (Negative = 0, Positive = 1).\n",
        "\n",
        "These metrics help understand how well the model identifies positive and negative reviews separately.\n",
        "\n",
        "## Print results:\n",
        "\n",
        "- Displays overall accuracy.\n",
        "\n",
        "- Shows a full classification report with key performance metrics."
      ],
      "metadata": {
        "id": "yGA9sefYUu0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_vec)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['Negative (0)', 'Positive (1)'])\n",
        "\n",
        "print(\"\\n--- Model Evaluation Results ---\")\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report (Key Metrics):\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuQ9YGqWSqB0",
        "outputId": "11df8672-77af-4778-a8cf-9b689e4b191d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Evaluation Results ---\n",
            "Overall Accuracy: 0.8300\n",
            "\n",
            "Classification Report (Key Metrics):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Negative (0)       0.85      0.81      0.83       200\n",
            "Positive (1)       0.81      0.85      0.83       200\n",
            "\n",
            "    accuracy                           0.83       400\n",
            "   macro avg       0.83      0.83      0.83       400\n",
            "weighted avg       0.83      0.83      0.83       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the prediction function predict_sentiment:\n",
        "\n",
        "- Takes a review (text), the vectorizer (TF-IDF), and the trained model.\n",
        "\n",
        "- Converts the review into a numerical vector using vectorizer.transform.\n",
        "\n",
        "- Uses the model to predict the sentiment: positive (1) or negative (0).\n",
        "\n",
        "- Converts the numerical prediction into a label (\"Positive\" or \"Negative\").\n",
        "\n",
        "- Calculates the confidence of the prediction from the model’s probabilities.\n",
        "\n",
        "- Prints the review, predicted sentiment, and confidence percentage in a clear format.\n",
        "\n",
        "## Test cases:\n",
        "\n",
        "- Positive review → the function should predict “Positive” with high confidence.\n",
        "\n",
        "- Negative review → the function should predict “Negative” with high confidence.\n",
        "\n",
        "- Mixed review → the function predicts whichever sentiment the model finds stronger."
      ],
      "metadata": {
        "id": "WVdCuemUwJt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review, vectorizer, model):\n",
        "\n",
        "    review_vec = vectorizer.transform([review])\n",
        "\n",
        "\n",
        "    prediction = model.predict(review_vec)[0]\n",
        "\n",
        "\n",
        "    sentiment_label = \"Positive\" if prediction == 1 else \"Negative\"\n",
        "\n",
        "\n",
        "    probability = model.predict_proba(review_vec)[0]\n",
        "    confidence = max(probability) * 100\n",
        "\n",
        "    print(\"-----------------------------------------------------\")\n",
        "    print(f\"Review: '{review}'\")\n",
        "    print(f\"Predicted Sentiment: **{sentiment_label}**\")\n",
        "    print(f\"Confidence: {confidence:.2f}%\")\n",
        "    print(\"-----------------------------------------------------\")\n",
        "\n",
        "\n",
        "# --- Test Cases ---\n",
        "# Case 1: Positive Review\n",
        "positive_review = \"This film was absolutely brilliant, the acting was superb and the story was gripping. A true masterpiece!\"\n",
        "predict_sentiment(positive_review, vectorizer, model)\n",
        "\n",
        "# Case 2: Negative Review\n",
        "negative_review = \"The movie was a complete waste of time. Terrible script, slow pace, and the ending made no sense at all.\"\n",
        "predict_sentiment(negative_review, vectorizer, model)\n",
        "\n",
        "# Case 3: Neutral/Mixed\n",
        "mixed_review = \"The special effects were great, but the plot dragged on forever and the main actor was unconvincing.\"\n",
        "predict_sentiment(mixed_review, vectorizer, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMz-402ySvlx",
        "outputId": "619c4645-0059-4c5e-84ec-fa0d59f2f405"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------\n",
            "Review: 'This film was absolutely brilliant, the acting was superb and the story was gripping. A true masterpiece!'\n",
            "Predicted Sentiment: **Positive**\n",
            "Confidence: 73.63%\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "Review: 'The movie was a complete waste of time. Terrible script, slow pace, and the ending made no sense at all.'\n",
            "Predicted Sentiment: **Negative**\n",
            "Confidence: 74.68%\n",
            "-----------------------------------------------------\n",
            "-----------------------------------------------------\n",
            "Review: 'The special effects were great, but the plot dragged on forever and the main actor was unconvincing.'\n",
            "Predicted Sentiment: **Negative**\n",
            "Confidence: 52.65%\n",
            "-----------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}